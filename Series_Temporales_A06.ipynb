{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LAB1 RNNs : Lucía Chicharro, María Montero y Patricia Ramos\n"
      ],
      "metadata": {
        "id": "8fpDADax3opB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haremos una **predicción de temperaturas** de **24 horas en el futuro**, dada una **serie temporal** de **medidas de cantidades** (cada hora) coeespondientes a **presión** y **humedad** recogidas en el **pasado reciente** por un conjunto de sensores en lo alto de un edificio.\n",
        "\n",
        "El dataset se ha obtenido de la estación meteorilógica del Max Plank Institure for Biogeochemistry en Jena, Alemania. [http://www.bgc-jena.mpg.de/wetter](http://www.bgc-jena.mpg.de/wetter)"
      ],
      "metadata": {
        "id": "EF75BP-c37dR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset se compone de 14 magnitudes, como temperatura, presión, humedad, dirección del viento, etc. grabadas cada 10' durante varios años (2009-2016). Descargamos y descomprimimos el dataset"
      ],
      "metadata": {
        "id": "doBk84rg4bl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2VKfbRvviat",
        "outputId": "8e1c7e44-3b55-4a49-f204-88ec101f8716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-27 20:28:53--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.111.126, 16.182.103.96, 52.217.121.192, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.111.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  47.5MB/s    in 0.3s    \n",
            "\n",
            "2024-02-27 20:28:53 (47.5 MB/s) - ‘jena_climate_2009_2016.csv.zip’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "  inflating: jena_climate_2009_2016.csv  \n",
            "  inflating: __MACOSX/._jena_climate_2009_2016.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Echamos un vistazo al dataset**"
      ],
      "metadata": {
        "id": "I5haJZ834hrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
        "\n",
        "with open(fname) as f:\n",
        "    data = f.read()\n",
        "\n",
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "print(header)\n",
        "print(len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb7xF8sDwNYj",
        "outputId": "d5cb895b-f191-4c16-ac2b-95380e513476"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"Date Time\"', '\"p (mbar)\"', '\"T (degC)\"', '\"Tpot (K)\"', '\"Tdew (degC)\"', '\"rh (%)\"', '\"VPmax (mbar)\"', '\"VPact (mbar)\"', '\"VPdef (mbar)\"', '\"sh (g/kg)\"', '\"H2OC (mmol/mol)\"', '\"rho (g/m**3)\"', '\"wv (m/s)\"', '\"max. wv (m/s)\"', '\"wd (deg)\"']\n",
            "420451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto devuelve una cuenta de 420.451 líneas de datos (cada línea es un timestep: un registro de una fecha con 14 valores relativos a las condiciones meteorológicas)"
      ],
      "metadata": {
        "id": "wmecMh1P4isq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parseamos los datos**"
      ],
      "metadata": {
        "id": "qghM4dAa4mPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "temperature = np.zeros((len(lines),))\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))\n",
        "for i, line in enumerate(lines):\n",
        "    values = [float(x) for x in line.split(\",\")[1:]]\n",
        "    # Guardamos columna 1 en el array temperatura\n",
        "    temperature[i] = values[1]\n",
        "    # Guardamos todas las columnas (temperatura\n",
        "    # incluida) en el array raw_data\n",
        "    raw_data[i, :] = values[:]"
      ],
      "metadata": {
        "id": "FMs1XR-RwJi-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, **convertimos** las 420.551 **líneas de datos** en **arrays NumPy**: **un array para** la **temperatura** (en Celsius), y **otro para el resto de los datos**-las características que usaremos para predecir futuras temperaturas. Notar que **hemos descartado** la columna **\"Date Time\"**"
      ],
      "metadata": {
        "id": "voAUcgqB4peF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computamos el número de muestras que usaremos para cada lote de datos**\n",
        "\n",
        "Usaremos el 50% para entrenar, el siguiente 25% para validar y el último 25% para las pruebas."
      ],
      "metadata": {
        "id": "MiFxezrb4zgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoglUmGP0Hyt",
        "outputId": "87df4a86-9534-418d-a345-2edcc0b82168"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_train_samples: 210225\n",
            "num_val_samples: 105112\n",
            "num_test_samples: 105114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación de los datos"
      ],
      "metadata": {
        "id": "L75gPIix4-Ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizando los datos**\n",
        "\n",
        "Dado que los datos están en escalas diferentes, normalizamos cada serie para que todas tomen valores pequeños en una escala similar."
      ],
      "metadata": {
        "id": "ukXhfaaL5Xnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "raw_data /= std"
      ],
      "metadata": {
        "id": "-0gl804N0Kw1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, **creamos un objeto ``Dataset``** que **produzca lotes** de datos de los **últimos cinco días** **junto con** una **temperatura objetivo** **dentro de las 24 horas siguientes**. Debido a que las **muestras** en el conjunto de datos son **altamente redundantes** (la muestra ``N`` y la muestra ``N + 1`` tendrán la mayoría de sus intervalos de tiempo en común), sería un desperdicio asignar memoria explícitamente para cada muestra. En su lugar, **generaremos las muestras sobre la marcha** y solo mantendremos en la memoria los arrays ``raw_data`` y de ``temperature`` originales, y nada más.\n",
        "\n",
        "Podríamos escribir fácilmente un generador de Python para hacer esto, pero hay una utilidad incorporada en Keras que hace exactamente eso (**``timeseries_dataset_from_array()``**), por lo que podemos ahorrarnos algo de trabajo al usarlo. Por lo general, se puede usar para cualquier tipo de tarea de pronóstico de series temporales."
      ],
      "metadata": {
        "id": "bqUS8WWw5t_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos ``timeseries_dataset_from_array()`` para instanciar tres datasets: uno para **entrenamiento**, otro para **validación** y otro para **prueba**.\n",
        "\n",
        "Usaremos los siguientes valores de parámetro:\n",
        "\n",
        "* ``sampling_rate = 6``: las observaciones se muestrearán en un punto de datos por hora: solo mantendremos un punto de datos de 6.\n",
        "* ``sequence_length = 120``: las observaciones retrocederán 5 días (120 horas).\n",
        "* ``delay = sampling_rate * (sequence_length + 24 - 1)``: el target de una secuencia será la temperatura 24 horas después del final de la secuencia."
      ],
      "metadata": {
        "id": "Jk6aLnY95vw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "sampling_rate = 6\n",
        "sequence_length = 120\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256\n",
        "\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=0,\n",
        "    end_index=num_train_samples)\n",
        "\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples)\n",
        "\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples)"
      ],
      "metadata": {
        "id": "cxIw-6aD0eYd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que el volumen de datos es demasiado grande como para poder trabajar con él sin emplear excesivo tiempo, de los 819 lotes de entrenamiento nos quedaremos con 50. De los lotes de validación con 25 y de los test otros 25."
      ],
      "metadata": {
        "id": "FSnksE0q50my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.take(50)\n",
        "val_dataset = val_dataset.take(25)\n",
        "test_dataset = test_dataset.take(25)"
      ],
      "metadata": {
        "id": "60yCqSbPv2h7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comenzando con un modelo de referencia con sentido común sin usar machine-learning\n",
        "\n"
      ],
      "metadata": {
        "id": "fskEWByv8rfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto servirá como línea base que se debe superar para demostrar la utilidad de los modelos de aprendizaje avanzado.\n",
        "\n",
        "En este caso, **se puede suponer con cierta seguridad que las series de tiempo de temperatura son continuas**, así como **también periódicas con un período diario**. Por lo tanto, **un enfoque de sentido común es predecir siempre que la temperatura dentro de 24 horas será igual a la temperatura en este momento**.\n",
        "\n",
        "Evaluemos este enfoque, utilizando la **métrica del error absoluto medio (MAE)**, definida de la siguiente manera:\n",
        "\n",
        "**np.mean(np.abs(preds - targets))**\n",
        "\n"
      ],
      "metadata": {
        "id": "JyqF9lnx9KSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_naive_method(dataset):\n",
        "    total_abs_err = 0.\n",
        "    samples_seen = 0\n",
        "    for samples, targets in dataset:\n",
        "        # La característica 'temperatura' está en la columna 1,\n",
        "        # por lo que samples[:, -1, 1] es la última medición de\n",
        "        # temperatura en la secuencia de entrada. Recordad que\n",
        "        # normalizamos nuestras características, por lo que para\n",
        "        # recuperar una temperatura en grados Celsius, debemos\n",
        "        # desnormalizarla multiplicándola por la desviación\n",
        "        # estándar y sumando nuevamente la media.\n",
        "        preds = samples[:, -1, 1] * std[1] + mean[1]\n",
        "        total_abs_err += np.sum(np.abs(preds - targets))\n",
        "        samples_seen += samples.shape[0]\n",
        "    return total_abs_err / samples_seen\n",
        "\n",
        "print(f\"Validation MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
        "print(f\"Test MAE: {evaluate_naive_method(test_dataset):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OU2kqOu0jFd",
        "outputId": "e00cf044-01b4-46ea-c616-6e82013c30e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAE: 2.46\n",
            "Test MAE: 2.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ha logrado un MAE de validación de 2,46 y de prueba 2,60. Pese a que no es un resultado totalmente adecuado, si lo comparamos con el modelo base que se ha obtenido sin delimitar el conjunto de datos; apenas hay alguna diferencia en las centésimas."
      ],
      "metadata": {
        "id": "24Vo4rUR-MLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo a ajustar.\n",
        "\n",
        "Dado que utilizando parámetros casi aleatorios se obtiene un modelo de capas apiladas con unidades recurrentes cerradas (GRU) que ya supera la línea base, vamos a ver si, modificando algún hiperparámetro, logramos obtener un MAE más bajo.\n",
        "\n",
        "Como hemos reducido notablemente la cantidad de datos, debemos disminuir el número de épocas para evitar que el modelo se sobreajuste.\n",
        "\n",
        "Con los hiperparámetros que ya se daban se obtiene:"
      ],
      "metadata": {
        "id": "TtPhM9ut_rcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "SUwYcb7SDd6R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny3QLXQRiror",
        "outputId": "9060ff7c-a0a0-43cc-d6a1-42bda7a319ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 30s 510ms/step - loss: 91.5006 - mae: 7.8145 - val_loss: 52.6964 - val_mae: 5.6212\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 25s 491ms/step - loss: 48.1216 - mae: 5.2997 - val_loss: 39.7283 - val_mae: 4.7758\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 22s 434ms/step - loss: 38.0075 - mae: 4.6479 - val_loss: 29.9505 - val_mae: 4.0577\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 24s 472ms/step - loss: 30.6286 - mae: 4.1438 - val_loss: 23.0141 - val_mae: 3.5251\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 22s 443ms/step - loss: 25.2698 - mae: 3.7916 - val_loss: 18.5792 - val_mae: 3.1999\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 24s 479ms/step - loss: 21.4450 - mae: 3.5277 - val_loss: 15.2633 - val_mae: 2.9198\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 22s 431ms/step - loss: 19.4078 - mae: 3.3752 - val_loss: 13.4251 - val_mae: 2.7587\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 23s 447ms/step - loss: 17.9998 - mae: 3.2634 - val_loss: 11.9447 - val_mae: 2.6233\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 24s 474ms/step - loss: 16.9589 - mae: 3.1692 - val_loss: 10.7752 - val_mae: 2.5027\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 26s 508ms/step - loss: 16.3677 - mae: 3.1333 - val_loss: 10.4506 - val_mae: 2.4823\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 23s 448ms/step - loss: 16.0456 - mae: 3.0995 - val_loss: 9.7408 - val_mae: 2.3986\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 24s 469ms/step - loss: 15.6066 - mae: 3.0653 - val_loss: 9.5209 - val_mae: 2.3688\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 24s 472ms/step - loss: 15.3335 - mae: 3.0332 - val_loss: 9.7390 - val_mae: 2.4023\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 25s 500ms/step - loss: 15.4011 - mae: 3.0494 - val_loss: 9.4172 - val_mae: 2.3743\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 26s 520ms/step - loss: 15.2848 - mae: 3.0214 - val_loss: 9.2834 - val_mae: 2.3496\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 25s 488ms/step - loss: 15.0116 - mae: 3.0077 - val_loss: 9.1374 - val_mae: 2.3332\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 24s 472ms/step - loss: 14.6590 - mae: 2.9702 - val_loss: 9.5633 - val_mae: 2.3997\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 25s 502ms/step - loss: 14.8232 - mae: 2.9764 - val_loss: 9.3320 - val_mae: 2.3590\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 25s 499ms/step - loss: 14.4862 - mae: 2.9494 - val_loss: 8.9965 - val_mae: 2.3218\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 25s 494ms/step - loss: 14.6508 - mae: 2.9630 - val_loss: 9.0568 - val_mae: 2.3324\n",
            "25/25 [==============================] - 4s 99ms/step - loss: 10.7207 - mae: 2.5426\n",
            "Test MAE: 2.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se obtiene un MAE de 2,54. Este es el valor que debemos mejorar."
      ],
      "metadata": {
        "id": "G_fyavmGA6hN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aumentamos el número de unidades"
      ],
      "metadata": {
        "id": "-vbCBxzn1qRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al aumentar el número de unidades, se aumenta la capacidad de apredizaje lo que puede llevar a aprender patrones complejos. Sin embargo, requiere mayor capacidad computacional o puede llevar a un sobreajuste del modelo.\n",
        "\n",
        "### Aumentamos a 50"
      ],
      "metadata": {
        "id": "TcHzx2U4BFkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVvs-jLX1L2j",
        "outputId": "39b60afd-d8b1-4811-935d-9b3e484bc3f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 37s 638ms/step - loss: 67.1910 - mae: 6.5345 - val_loss: 31.8657 - val_mae: 4.3140\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 29.3321 - mae: 4.1328 - val_loss: 20.7911 - val_mae: 3.4122\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 22.0187 - mae: 3.5833 - val_loss: 15.3592 - val_mae: 2.9410\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 31s 613ms/step - loss: 18.2992 - mae: 3.2969 - val_loss: 12.2456 - val_mae: 2.6578\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 38s 754ms/step - loss: 16.7297 - mae: 3.1738 - val_loss: 10.8098 - val_mae: 2.5035\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 37s 728ms/step - loss: 15.4670 - mae: 3.0629 - val_loss: 10.2150 - val_mae: 2.4661\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 32s 627ms/step - loss: 14.9480 - mae: 3.0046 - val_loss: 9.6268 - val_mae: 2.3886\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 32s 645ms/step - loss: 13.9447 - mae: 2.9237 - val_loss: 9.2563 - val_mae: 2.3477\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 33s 645ms/step - loss: 14.0172 - mae: 2.9129 - val_loss: 9.3724 - val_mae: 2.3681\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 13.6553 - mae: 2.8823 - val_loss: 9.0268 - val_mae: 2.3238\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 32s 630ms/step - loss: 13.5578 - mae: 2.8621 - val_loss: 9.4583 - val_mae: 2.3757\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 32s 636ms/step - loss: 13.6941 - mae: 2.8737 - val_loss: 9.0510 - val_mae: 2.3197\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 13.2128 - mae: 2.8329 - val_loss: 9.0572 - val_mae: 2.3219\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 32s 625ms/step - loss: 13.3424 - mae: 2.8488 - val_loss: 9.1410 - val_mae: 2.3311\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 638ms/step - loss: 13.2986 - mae: 2.8387 - val_loss: 9.5281 - val_mae: 2.3855\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 645ms/step - loss: 13.2777 - mae: 2.8376 - val_loss: 8.8880 - val_mae: 2.3051\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 34s 670ms/step - loss: 12.9484 - mae: 2.8069 - val_loss: 9.1066 - val_mae: 2.3260\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 38s 758ms/step - loss: 12.9205 - mae: 2.7982 - val_loss: 8.8784 - val_mae: 2.2936\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 31s 616ms/step - loss: 12.6534 - mae: 2.7626 - val_loss: 8.8877 - val_mae: 2.2947\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 12.8701 - mae: 2.7879 - val_loss: 8.7124 - val_mae: 2.2830\n",
            "25/25 [==============================] - 5s 143ms/step - loss: 9.7327 - mae: 2.4276\n",
            "Test MAE: 2.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentando a 50 unidades hemos obtenido un MAE de 2,43. Este valor es mucho mejor que el inicial. Sin embargo, debemos comprobar si con menos unidades logramos resultados parecidos con menos coste computacional."
      ],
      "metadata": {
        "id": "VC9YkOMEVvPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aumentamos a 40"
      ],
      "metadata": {
        "id": "0fgsAuXHVpZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(40, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(40, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9KeymoD5GoW",
        "outputId": "a6127f6a-16a9-4671-b308-3568081af877"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 40s 662ms/step - loss: 82.1477 - mae: 7.3050 - val_loss: 44.8907 - val_mae: 5.1539\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 29s 586ms/step - loss: 40.7544 - mae: 4.8439 - val_loss: 31.7218 - val_mae: 4.2031\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 27s 529ms/step - loss: 30.9880 - mae: 4.2198 - val_loss: 22.9626 - val_mae: 3.5602\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 24.4426 - mae: 3.7453 - val_loss: 17.9158 - val_mae: 3.1876\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 27s 545ms/step - loss: 20.1172 - mae: 3.4333 - val_loss: 14.0588 - val_mae: 2.8163\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 27s 537ms/step - loss: 17.9329 - mae: 3.2633 - val_loss: 11.9516 - val_mae: 2.6360\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 27s 540ms/step - loss: 16.7165 - mae: 3.1615 - val_loss: 10.7482 - val_mae: 2.4990\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 27s 539ms/step - loss: 15.6933 - mae: 3.0801 - val_loss: 10.0818 - val_mae: 2.4342\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 26s 509ms/step - loss: 15.2032 - mae: 3.0325 - val_loss: 9.8203 - val_mae: 2.4101\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 26s 515ms/step - loss: 14.7484 - mae: 2.9936 - val_loss: 9.7342 - val_mae: 2.4019\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 27s 538ms/step - loss: 14.4910 - mae: 2.9733 - val_loss: 9.3144 - val_mae: 2.3459\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 27s 544ms/step - loss: 14.2431 - mae: 2.9286 - val_loss: 9.0769 - val_mae: 2.3309\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 25s 494ms/step - loss: 14.3734 - mae: 2.9389 - val_loss: 9.1491 - val_mae: 2.3526\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 27s 529ms/step - loss: 14.1178 - mae: 2.9353 - val_loss: 9.1579 - val_mae: 2.3358\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 26s 509ms/step - loss: 14.0187 - mae: 2.9202 - val_loss: 9.1209 - val_mae: 2.3401\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 26s 510ms/step - loss: 13.9612 - mae: 2.9042 - val_loss: 9.0154 - val_mae: 2.3116\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 26s 511ms/step - loss: 13.6837 - mae: 2.8680 - val_loss: 8.9577 - val_mae: 2.3114\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 27s 537ms/step - loss: 13.7184 - mae: 2.8813 - val_loss: 9.0930 - val_mae: 2.3307\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 27s 535ms/step - loss: 13.4407 - mae: 2.8492 - val_loss: 8.8383 - val_mae: 2.2973\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 27s 537ms/step - loss: 13.8185 - mae: 2.8862 - val_loss: 8.9961 - val_mae: 2.3153\n",
            "25/25 [==============================] - 4s 116ms/step - loss: 10.2757 - mae: 2.4842\n",
            "Test MAE: 2.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al disminuir el número de unidades ha aumentado el MAE por lo que 50 es el número óptimo de aumento."
      ],
      "metadata": {
        "id": "3iN7ZSYlY27J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disminuimos el número de unidades"
      ],
      "metadata": {
        "id": "4f-C565s8EE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pese a que al aumentar se han obtenido mejores resultados, es necesario comprobar si con menos unidades los resultados mejoran o empeoran.\n",
        "\n"
      ],
      "metadata": {
        "id": "imptKwLeZCSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disminuimos a 16"
      ],
      "metadata": {
        "id": "IHmdQGYJZPpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(16, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(16, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHX_G0bP8Ghu",
        "outputId": "caafd65a-1062-4009-cadb-3b037e264451"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 24s 379ms/step - loss: 120.0292 - mae: 9.0793 - val_loss: 90.6517 - val_mae: 7.8186\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 19s 374ms/step - loss: 78.8902 - mae: 6.9808 - val_loss: 69.7317 - val_mae: 6.5244\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 18s 348ms/step - loss: 66.0857 - mae: 6.2552 - val_loss: 59.0940 - val_mae: 5.9537\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 57.6476 - mae: 5.7957 - val_loss: 52.3978 - val_mae: 5.5118\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 17s 345ms/step - loss: 51.7977 - mae: 5.4253 - val_loss: 43.9925 - val_mae: 4.9935\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 20s 396ms/step - loss: 45.4823 - mae: 5.0646 - val_loss: 38.5028 - val_mae: 4.6102\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 16s 313ms/step - loss: 40.6596 - mae: 4.7741 - val_loss: 33.7975 - val_mae: 4.3068\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 18s 350ms/step - loss: 37.1903 - mae: 4.5597 - val_loss: 29.5053 - val_mae: 3.9897\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 16s 314ms/step - loss: 33.2617 - mae: 4.3011 - val_loss: 25.6149 - val_mae: 3.7187\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 19s 366ms/step - loss: 30.6239 - mae: 4.1261 - val_loss: 22.8236 - val_mae: 3.4877\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 28.0270 - mae: 3.9540 - val_loss: 20.0735 - val_mae: 3.2856\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 19s 372ms/step - loss: 26.2597 - mae: 3.8516 - val_loss: 17.8428 - val_mae: 3.1369\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 24.4570 - mae: 3.7213 - val_loss: 16.3185 - val_mae: 2.9808\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 22.8952 - mae: 3.6045 - val_loss: 14.8578 - val_mae: 2.8583\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 22.3460 - mae: 3.5655 - val_loss: 13.3918 - val_mae: 2.7341\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 16s 319ms/step - loss: 20.9829 - mae: 3.4906 - val_loss: 13.0356 - val_mae: 2.7022\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 16s 314ms/step - loss: 20.6460 - mae: 3.4550 - val_loss: 11.6873 - val_mae: 2.5714\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 19s 365ms/step - loss: 20.0854 - mae: 3.4211 - val_loss: 11.7916 - val_mae: 2.5807\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 16s 316ms/step - loss: 19.5221 - mae: 3.3775 - val_loss: 11.1989 - val_mae: 2.5332\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 19s 370ms/step - loss: 19.4724 - mae: 3.3648 - val_loss: 10.9970 - val_mae: 2.5153\n",
            "25/25 [==============================] - 3s 76ms/step - loss: 13.7149 - mae: 2.7731\n",
            "Test MAE: 2.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al disminuir tanto las unidades, no se tienen suficientes como para realizar un proceso de aprendizaje adecuado. Por tanto, vamos a probar a no bajar demasiado ese número."
      ],
      "metadata": {
        "id": "3n_xGxsZahyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disminuimos a 25"
      ],
      "metadata": {
        "id": "2babnWB3ZaDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(25, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(25, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLSxWgZO8M14",
        "outputId": "786e22a4-4ca6-4bc4-e772-8228cbc5b5af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 27s 441ms/step - loss: 92.7743 - mae: 7.9316 - val_loss: 53.1052 - val_mae: 5.6346\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 20s 401ms/step - loss: 50.4014 - mae: 5.4199 - val_loss: 42.2064 - val_mae: 4.9558\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 19s 385ms/step - loss: 41.3575 - mae: 4.8506 - val_loss: 34.0485 - val_mae: 4.3726\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 20s 390ms/step - loss: 34.7205 - mae: 4.4448 - val_loss: 27.6227 - val_mae: 3.8764\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 22s 429ms/step - loss: 29.4053 - mae: 4.0910 - val_loss: 22.2235 - val_mae: 3.4657\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 24s 468ms/step - loss: 25.5852 - mae: 3.8255 - val_loss: 18.7076 - val_mae: 3.1953\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 23s 456ms/step - loss: 23.2810 - mae: 3.6625 - val_loss: 16.1238 - val_mae: 2.9758\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 21s 405ms/step - loss: 20.6094 - mae: 3.4772 - val_loss: 14.0181 - val_mae: 2.7917\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 22s 433ms/step - loss: 19.8580 - mae: 3.4151 - val_loss: 12.6306 - val_mae: 2.6693\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 19s 384ms/step - loss: 18.7743 - mae: 3.3202 - val_loss: 11.5917 - val_mae: 2.5775\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 21s 414ms/step - loss: 17.7244 - mae: 3.2415 - val_loss: 10.9613 - val_mae: 2.5174\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 25s 498ms/step - loss: 17.0629 - mae: 3.1814 - val_loss: 10.4471 - val_mae: 2.4845\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 23s 462ms/step - loss: 17.2496 - mae: 3.2006 - val_loss: 10.3117 - val_mae: 2.4602\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 26s 521ms/step - loss: 16.6652 - mae: 3.1542 - val_loss: 9.7185 - val_mae: 2.3853\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 19s 383ms/step - loss: 16.5558 - mae: 3.1438 - val_loss: 9.6765 - val_mae: 2.3847\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 20s 385ms/step - loss: 15.9982 - mae: 3.0949 - val_loss: 9.5155 - val_mae: 2.3714\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 19s 378ms/step - loss: 16.0381 - mae: 3.1088 - val_loss: 9.5301 - val_mae: 2.3825\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 20s 404ms/step - loss: 16.2828 - mae: 3.1046 - val_loss: 9.3791 - val_mae: 2.3628\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 22s 438ms/step - loss: 16.1696 - mae: 3.1082 - val_loss: 9.4063 - val_mae: 2.3653\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 20s 389ms/step - loss: 15.7526 - mae: 3.0647 - val_loss: 9.1739 - val_mae: 2.3409\n",
            "25/25 [==============================] - 4s 127ms/step - loss: 10.9621 - mae: 2.5531\n",
            "Test MAE: 2.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al obtener 2,55 de MAE podemos concluir que, aumentar el número de unidades, es más beneficioso para la predicción que disminuirlo."
      ],
      "metadata": {
        "id": "hQvMbz2VdBS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modificamos el dropout"
      ],
      "metadata": {
        "id": "_QxLv7DF8gyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otro hiperparámetro que podemos modificar es el dropout. Esto consiste en poner a cero las unidades de entrada de una capa de manera que se evite el sobreentrenamiento.\n",
        "Normalmente el dropout no suele superar el 0.5. Además, en este caso al no contar con muchos datos poner más de la mitad de las entradas a cero seguro repercute negativamente en el resultado.\n",
        "\n",
        "Por tanto, probaremos un dropout de 0,3."
      ],
      "metadata": {
        "id": "NFnSGRqObRRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.3)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRjpmsV2dHLQ",
        "outputId": "ec2a3bb9-b0ed-4c14-b7a0-a6fc4dd1b581"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 36s 632ms/step - loss: 71.6423 - mae: 6.6610 - val_loss: 38.9475 - val_mae: 4.7640\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 39s 772ms/step - loss: 33.3525 - mae: 4.3727 - val_loss: 24.9508 - val_mae: 3.7261\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 23.5832 - mae: 3.6728 - val_loss: 17.6417 - val_mae: 3.1133\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 17.9625 - mae: 3.2337 - val_loss: 13.9116 - val_mae: 2.8126\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 14.8556 - mae: 2.9719 - val_loss: 10.8978 - val_mae: 2.4953\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 32s 631ms/step - loss: 13.5993 - mae: 2.8689 - val_loss: 10.2583 - val_mae: 2.4361\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 39s 786ms/step - loss: 12.8520 - mae: 2.8040 - val_loss: 9.6096 - val_mae: 2.3795\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 37s 739ms/step - loss: 12.3678 - mae: 2.7506 - val_loss: 9.2133 - val_mae: 2.3434\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 35s 679ms/step - loss: 12.1478 - mae: 2.7340 - val_loss: 9.0649 - val_mae: 2.3229\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 39s 774ms/step - loss: 11.8681 - mae: 2.6867 - val_loss: 9.1587 - val_mae: 2.3424\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 33s 648ms/step - loss: 11.6742 - mae: 2.6761 - val_loss: 9.0788 - val_mae: 2.3178\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 11.5671 - mae: 2.6651 - val_loss: 9.2685 - val_mae: 2.3461\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 11.5001 - mae: 2.6617 - val_loss: 9.0397 - val_mae: 2.3141\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 32s 628ms/step - loss: 11.2335 - mae: 2.6265 - val_loss: 8.7652 - val_mae: 2.2850\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 11.1304 - mae: 2.6115 - val_loss: 8.8142 - val_mae: 2.2879\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 11.1798 - mae: 2.6169 - val_loss: 8.6930 - val_mae: 2.2658\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 32s 637ms/step - loss: 10.8243 - mae: 2.5778 - val_loss: 9.1168 - val_mae: 2.3206\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 32s 629ms/step - loss: 10.9450 - mae: 2.5785 - val_loss: 8.7667 - val_mae: 2.2775\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 34s 673ms/step - loss: 10.8666 - mae: 2.5796 - val_loss: 8.7908 - val_mae: 2.2787\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 32s 638ms/step - loss: 10.6838 - mae: 2.5492 - val_loss: 8.9812 - val_mae: 2.3041\n",
            "25/25 [==============================] - 6s 172ms/step - loss: 9.9501 - mae: 2.4509\n",
            "Test MAE: 2.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El hecho de que no haya mejorado sustancialmente, quizás se puede explicar debido a que el posible sobreajuste que se puede provocar aumentando las unidades se contrasta con un dropout más alto. Por tanto, si considerásemos mejor opción menos unidades, se debería reducir el dropout y comprobar los resultados."
      ],
      "metadata": {
        "id": "XcvKPRJ8gCCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modificamos el learning_rate"
      ],
      "metadata": {
        "id": "GpJ0oyI2eDCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta tasa indica cada cuánto se ajustan los pesos y se minimiza la pérdida. Si es demasiado pequeña puede quedarse en un mínimo local, mientras que si es demasiado grande nunca llegará al mínimo."
      ],
      "metadata": {
        "id": "wgksh0u-eHa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLTRqcYRJbeQ",
        "outputId": "0a6d0985-c7ea-486c-ced9-bbd1ee02d70d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 45s 776ms/step - loss: 67.2501 - mae: 6.4761 - val_loss: 31.1041 - val_mae: 4.2465\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 38s 749ms/step - loss: 29.8619 - mae: 4.1765 - val_loss: 20.7982 - val_mae: 3.3950\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 34s 678ms/step - loss: 22.0159 - mae: 3.5786 - val_loss: 15.4117 - val_mae: 2.9628\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 32s 641ms/step - loss: 18.2107 - mae: 3.2912 - val_loss: 12.3884 - val_mae: 2.6732\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 16.0633 - mae: 3.1123 - val_loss: 10.6599 - val_mae: 2.4794\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 15.3348 - mae: 3.0375 - val_loss: 10.4421 - val_mae: 2.4766\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 32s 636ms/step - loss: 14.6524 - mae: 2.9917 - val_loss: 9.5730 - val_mae: 2.3829\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 14.0449 - mae: 2.9178 - val_loss: 9.2561 - val_mae: 2.3441\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 14.0452 - mae: 2.9167 - val_loss: 9.2328 - val_mae: 2.3487\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 32s 631ms/step - loss: 13.6940 - mae: 2.8856 - val_loss: 9.2968 - val_mae: 2.3504\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 32s 629ms/step - loss: 13.4733 - mae: 2.8578 - val_loss: 9.1483 - val_mae: 2.3373\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 31s 627ms/step - loss: 13.4978 - mae: 2.8577 - val_loss: 9.3865 - val_mae: 2.3743\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 31s 626ms/step - loss: 13.0176 - mae: 2.8219 - val_loss: 9.3754 - val_mae: 2.3750\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 34s 667ms/step - loss: 13.0651 - mae: 2.8113 - val_loss: 10.2159 - val_mae: 2.4934\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 12.9984 - mae: 2.8014 - val_loss: 8.9798 - val_mae: 2.3158\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 12.8810 - mae: 2.7990 - val_loss: 9.0117 - val_mae: 2.3226\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 32s 628ms/step - loss: 12.8642 - mae: 2.7956 - val_loss: 9.9185 - val_mae: 2.4323\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 32s 629ms/step - loss: 12.7284 - mae: 2.7863 - val_loss: 8.8581 - val_mae: 2.2944\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 31s 609ms/step - loss: 12.8587 - mae: 2.7890 - val_loss: 9.1334 - val_mae: 2.3274\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 33s 638ms/step - loss: 12.7741 - mae: 2.7806 - val_loss: 9.5647 - val_mae: 2.3907\n",
            "25/25 [==============================] - 5s 140ms/step - loss: 10.0261 - mae: 2.4653\n",
            "Test MAE: 2.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con respecto a la configuración que hemos determinado como última referencia, no supone mejora en el MAE.\n",
        "\n",
        "Aumentemos este valor."
      ],
      "metadata": {
        "id": "7mMfHWOui8NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9iF8U_7Jbno",
        "outputId": "c9e51768-3ef9-4b62-ef46-9c54a1738da9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 47s 825ms/step - loss: 28.5115 - mae: 4.0017 - val_loss: 10.9267 - val_mae: 2.5347\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 16.6862 - mae: 3.2106 - val_loss: 9.7124 - val_mae: 2.4168\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 15.5318 - mae: 3.0952 - val_loss: 9.3883 - val_mae: 2.3626\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 14.4453 - mae: 2.9863 - val_loss: 10.0897 - val_mae: 2.4803\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 32s 633ms/step - loss: 14.4307 - mae: 2.9671 - val_loss: 9.7842 - val_mae: 2.4215\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 13.7979 - mae: 2.9006 - val_loss: 9.4905 - val_mae: 2.3971\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 32s 629ms/step - loss: 13.1911 - mae: 2.8417 - val_loss: 10.0710 - val_mae: 2.4931\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 32s 643ms/step - loss: 12.9812 - mae: 2.8194 - val_loss: 9.1103 - val_mae: 2.3663\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 37s 739ms/step - loss: 12.6108 - mae: 2.7850 - val_loss: 9.2873 - val_mae: 2.3627\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 31s 620ms/step - loss: 12.1876 - mae: 2.7360 - val_loss: 10.2403 - val_mae: 2.5043\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 32s 630ms/step - loss: 12.2732 - mae: 2.7357 - val_loss: 9.7799 - val_mae: 2.4328\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 32s 631ms/step - loss: 11.9600 - mae: 2.7097 - val_loss: 10.0732 - val_mae: 2.4813\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 11.4759 - mae: 2.6457 - val_loss: 10.5861 - val_mae: 2.5426\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 33s 668ms/step - loss: 11.4811 - mae: 2.6457 - val_loss: 10.2654 - val_mae: 2.5157\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 11.3455 - mae: 2.6411 - val_loss: 9.5889 - val_mae: 2.3917\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 630ms/step - loss: 10.9477 - mae: 2.5831 - val_loss: 9.9223 - val_mae: 2.4588\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 32s 637ms/step - loss: 10.6312 - mae: 2.5461 - val_loss: 11.5199 - val_mae: 2.6545\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 33s 660ms/step - loss: 10.7325 - mae: 2.5433 - val_loss: 10.3790 - val_mae: 2.4972\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 32s 628ms/step - loss: 10.7153 - mae: 2.5415 - val_loss: 10.0259 - val_mae: 2.4855\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 31s 620ms/step - loss: 10.4521 - mae: 2.5152 - val_loss: 10.2214 - val_mae: 2.4877\n",
            "25/25 [==============================] - 5s 140ms/step - loss: 10.8439 - mae: 2.5752\n",
            "Test MAE: 2.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como conclusión, se puede suponer que para este caso concreto un learning rate más pequeño favorece el aprendizaje del modelo.\n",
        "\n",
        "Finalmente cambiaremos al optimizador Adam."
      ],
      "metadata": {
        "id": "p7Gaqs_QmDid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F2lb-ogmheq",
        "outputId": "75eca0b5-6575-4d3d-9bf9-ca1fe4b3b533"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 38s 634ms/step - loss: 94.3170 - mae: 8.0826 - val_loss: 41.3988 - val_mae: 5.1043\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 31s 612ms/step - loss: 34.5124 - mae: 4.5172 - val_loss: 24.0830 - val_mae: 3.7081\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 31s 612ms/step - loss: 24.7687 - mae: 3.7950 - val_loss: 17.6214 - val_mae: 3.1550\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 32s 636ms/step - loss: 20.6992 - mae: 3.4741 - val_loss: 15.0315 - val_mae: 2.9098\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 34s 668ms/step - loss: 18.5440 - mae: 3.3111 - val_loss: 12.8139 - val_mae: 2.6962\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 32s 640ms/step - loss: 17.4906 - mae: 3.2317 - val_loss: 11.8063 - val_mae: 2.5964\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 16.1047 - mae: 3.1098 - val_loss: 10.8817 - val_mae: 2.5062\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 15.6984 - mae: 3.0678 - val_loss: 10.5241 - val_mae: 2.4631\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 32s 631ms/step - loss: 15.0722 - mae: 3.0068 - val_loss: 10.2288 - val_mae: 2.4409\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 33s 657ms/step - loss: 15.0712 - mae: 3.0176 - val_loss: 9.9752 - val_mae: 2.4259\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 33s 656ms/step - loss: 14.5940 - mae: 2.9735 - val_loss: 9.8479 - val_mae: 2.4063\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 32s 640ms/step - loss: 14.2825 - mae: 2.9368 - val_loss: 9.6477 - val_mae: 2.3827\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 32s 644ms/step - loss: 13.8638 - mae: 2.8932 - val_loss: 9.5547 - val_mae: 2.3746\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 34s 683ms/step - loss: 13.7046 - mae: 2.8919 - val_loss: 9.5297 - val_mae: 2.3636\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 642ms/step - loss: 13.5984 - mae: 2.8833 - val_loss: 9.2545 - val_mae: 2.3387\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 643ms/step - loss: 13.5373 - mae: 2.8753 - val_loss: 9.4339 - val_mae: 2.3661\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 32s 640ms/step - loss: 13.6832 - mae: 2.8784 - val_loss: 9.2158 - val_mae: 2.3328\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 32s 641ms/step - loss: 13.4911 - mae: 2.8611 - val_loss: 9.1010 - val_mae: 2.3251\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 32s 632ms/step - loss: 12.9152 - mae: 2.8020 - val_loss: 9.2495 - val_mae: 2.3280\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 32s 636ms/step - loss: 13.2179 - mae: 2.8177 - val_loss: 9.0121 - val_mae: 2.3106\n",
            "25/25 [==============================] - 5s 136ms/step - loss: 10.5519 - mae: 2.5183\n",
            "Test MAE: 2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiando el optimizador no se consigue mejorar el MAE."
      ],
      "metadata": {
        "id": "EAp5zTGkps24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capas Dense"
      ],
      "metadata": {
        "id": "oyTny9ncp1H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(50, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
        "x = layers.GRU(50, recurrent_dropout=0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense (32)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"jena_stacked_gru_dropout.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=callbacks)\n",
        "model = keras.models.load_model(\"jena_stacked_gru_dropout.keras\")\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md6s314hqB-R",
        "outputId": "29381228-6394-4377-c763-7609a1c9a09d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 36s 608ms/step - loss: 46.1398 - mae: 5.1591 - val_loss: 12.5734 - val_mae: 2.7757\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 32s 634ms/step - loss: 17.0247 - mae: 3.2350 - val_loss: 9.9500 - val_mae: 2.4534\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 31s 625ms/step - loss: 15.3097 - mae: 3.0651 - val_loss: 9.6416 - val_mae: 2.4172\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 32s 639ms/step - loss: 14.5791 - mae: 2.9915 - val_loss: 9.5526 - val_mae: 2.4045\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 32s 635ms/step - loss: 14.4736 - mae: 2.9786 - val_loss: 10.7394 - val_mae: 2.5779\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 32s 629ms/step - loss: 13.9149 - mae: 2.9262 - val_loss: 9.6307 - val_mae: 2.4202\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 36s 711ms/step - loss: 13.7197 - mae: 2.8968 - val_loss: 8.9703 - val_mae: 2.3373\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 33s 640ms/step - loss: 13.4463 - mae: 2.8650 - val_loss: 8.9847 - val_mae: 2.3335\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 33s 651ms/step - loss: 13.0609 - mae: 2.8274 - val_loss: 9.3177 - val_mae: 2.3750\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 34s 669ms/step - loss: 13.3314 - mae: 2.8455 - val_loss: 9.4320 - val_mae: 2.3922\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 33s 667ms/step - loss: 13.1341 - mae: 2.8314 - val_loss: 8.8593 - val_mae: 2.3108\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 33s 657ms/step - loss: 12.8441 - mae: 2.8016 - val_loss: 8.8111 - val_mae: 2.3063\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 38s 764ms/step - loss: 13.0590 - mae: 2.8146 - val_loss: 8.8607 - val_mae: 2.3079\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 34s 669ms/step - loss: 12.5207 - mae: 2.7663 - val_loss: 8.7705 - val_mae: 2.2988\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 32s 630ms/step - loss: 12.4777 - mae: 2.7548 - val_loss: 8.8722 - val_mae: 2.3164\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 32s 637ms/step - loss: 12.4787 - mae: 2.7545 - val_loss: 8.5633 - val_mae: 2.2679\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 32s 631ms/step - loss: 12.3079 - mae: 2.7508 - val_loss: 9.1048 - val_mae: 2.3471\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 32s 639ms/step - loss: 12.4388 - mae: 2.7435 - val_loss: 8.8525 - val_mae: 2.3074\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 33s 649ms/step - loss: 12.0023 - mae: 2.7008 - val_loss: 9.0036 - val_mae: 2.3282\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 30s 605ms/step - loss: 11.8983 - mae: 2.6931 - val_loss: 9.1651 - val_mae: 2.3637\n",
            "25/25 [==============================] - 5s 158ms/step - loss: 9.7146 - mae: 2.4199\n",
            "Test MAE: 2.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al añadir una capa Dense intermedia permitimos al modelo aprender patrones más específicos y conocer información extra que con respecto a las RNN. Como resultado, se obtiene el mejor MAE."
      ],
      "metadata": {
        "id": "O1tO7xnGtckB"
      }
    }
  ]
}